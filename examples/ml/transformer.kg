:" Transformer implementation in pure Klong "
.pyf("numpy";"random");rns::.pya(random;"seed");rna::.pya(random;"rand")

:" TODO: implement Klong exp "
.pyf("numpy";["exp"])

:" Set Numpy Random seed to 42 "
rns(42)

:" Define the dimension appropriate operations we need "
max::{{,x@*>x}'x}
sum::{{,+/x}'x}

:"Define the softmax function"
softmax::{[ex];
    ex::exp(x - max(x));
    ex % sum(ex)
}

:"Define dot product"
dot::{[T];T::+y;{{+/x*y}(x;)'T}'x}

:"Square root"
sqr::{[a];a::x;:[0=x;0;{(x+a%x)%2}:~a]}

:"Define the scaled dot-product attention"
attention::{[Q K V dk scores weights];
    Q::x;K::y;V::z;
    dk::#Q@1;
    scores::dot(Q;+K)%sqr(dk);
    weights::softmax(scores);
    dot(weights; V)
}

:" Define a simple transformer "
transformer::{[Q K V attended];
    Q::dot(x; y@0);
    K::dot(x; y@1);
    V::dot(x; y@2);
    attended::attention(Q; K; V);
    dot(attended; y@3)
}

:"Initialize parameters"
batchsize::5
inputdim::10
hiddendim::20

:"Define the weights q, k, v, o"
q::rna(inputdim;hiddendim)
k::rna(inputdim;hiddendim)
v::rna(inputdim;hiddendim)
o::rna(hiddendim;inputdim)

:"Define the input data"
inputdata::rna(batchsize;inputdim)

:"Run the forward pass"
output::transformer(inputdata; (,q),(,k),(,v),(,o))

.d("output: ");.p(output)
